{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.output_parsers import StructuredOutputParser\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import json\n",
    "import re\n",
    "import tiktoken\n",
    "from Levenshtein import distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key = os.environ['OPENAI_API_KEY']\n",
    "llm_model = \"gpt-4\"\n",
    "\n",
    "def get_completion(prompt, model=llm_model):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(\"docs/Biometric Vehicle Access System.pdf\")\n",
    "example_abstract = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.get_encoding(\"cl100k_base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \"Biometric Vehicle Access System technology\"\n",
      "2. \"Advanced biometric authentication in vehicles\"\n",
      "3. \"Biometric sensors in door handles and ignition systems\"\n",
      "4. \"Anti-spoofing measures in vehicle access\"\n",
      "5. \"Integration of biometrics in smart vehicles\"\n"
     ]
    }
   ],
   "source": [
    "prompt1 = f\"\"\"```{example_abstract}```\\\n",
    "The abstract above describes a concept for a novel invention.\\\n",
    "I would like to search a patent database to find out whether \\\n",
    "there are already patents for such a concept. Name 5 phrases that I can \\\n",
    "use for the search. Each phrase should contain between 5 to 10 words. \\\n",
    "Optimize the phrases to get back more results.\n",
    "\"\"\"\n",
    "\n",
    "keywords = get_completion(prompt1)\n",
    "\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. G06K9/00\n",
      "2. B60R25/10\n",
      "3. G07C9/00\n",
      "4. E05B49/00\n",
      "5. G06F21/32\n"
     ]
    }
   ],
   "source": [
    "prompt2 = f\"\"\"```{example_abstract}```\\\n",
    "The abstract above describes a concept for a novel invention.\\\n",
    "I would like to search a patent database to find out whether \\\n",
    "there are already patents for such a concept. Please list me the codes of the 5 most relevant \\\n",
    "USPTO classifications to a possible patent for this concept without explanations for the codes.\n",
    "\"\"\"\n",
    "\n",
    "classifications = get_completion(prompt2)\n",
    "\n",
    "print(classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1 :  Method and system for localizing parts of an object in an image for computer …\n",
      "https://patentimages.storage.googleapis.com/a2/95/38/bcc3b288e56669/US9275273.pdf \n",
      "\n",
      "Result 2 :  Adaptive multi-modal integrated biometric identification and surveillance …\n",
      "https://patentimages.storage.googleapis.com/98/f0/22/ae169ef67be168/US9432632.pdf \n",
      "\n",
      "Result 3 :  Spoof detection for biometric authentication\n",
      "https://patentimages.storage.googleapis.com/84/29/92/5fe2a153298d2d/US9971920.pdf \n",
      "\n",
      "Result 4 :  Liveness testing methods and apparatuses and image processing methods and …\n",
      "https://patentimages.storage.googleapis.com/b1/98/34/94c48fd1f99eeb/US11151397.pdf \n",
      "\n",
      "Result 5 :  Biometrics based on locally consistent features\n",
      "https://patentimages.storage.googleapis.com/a6/11/c7/5583de7c8fb29d/US9060688.pdf \n",
      "\n",
      "Result 6 :  System and method for detecting the authenticity of products\n",
      "https://patentimages.storage.googleapis.com/9c/e5/fc/eb90d460e518de/US10956732.pdf \n",
      "\n",
      "Result 7 :  System and process for automatically analyzing currency objects\n",
      "https://patentimages.storage.googleapis.com/da/c5/41/ea81c81c813087/US10504073.pdf \n",
      "\n",
      "Result 8 :  Application of Z-webs and Z-factors to analytics, search engine, learning, …\n",
      "https://patentimages.storage.googleapis.com/7a/fb/91/5ff09b40c62ec6/US8873813.pdf \n",
      "\n",
      "Result 9 :  Portable biometric identification device using a dorsal hand vein pattern\n",
      "https://patentimages.storage.googleapis.com/7c/30/05/2dc2f874122207/US9095285.pdf \n",
      "\n",
      "Result 10 :  Methods and systems for content processing\n",
      "https://patentimages.storage.googleapis.com/85/75/62/8ef916adcc3d18/US10922957.pdf \n",
      "\n"
     ]
    }
   ],
   "source": [
    "f = open('data_dump/test.json')\n",
    "data = json.load(f)\n",
    "\n",
    "for i in data['organic_results']:\n",
    "\n",
    "    print(\"Result\", i['position'], \": \", i['title'])\n",
    "    # print(i['snippet'], \"\\n\")\n",
    "    print(i['pdf'], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_list = []\n",
    "for i in data['organic_results']:\n",
    "    loader = PyPDFLoader(i['pdf'])\n",
    "    pdf = loader.load_and_split()\n",
    "    pdf_list.append(pdf[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1 Clean Abstract: A system is provided for localizing parts of an object in an image by training local detectors using labeled image exem plars with fiducial points corresponding to parts within the image. Each local detector generates a detector score corre sponding to the likelihood that a desired part is located at a given location within the image exemplar. A non-parametric global model of the locations of the fiducial points is gener ated for each of at least a portion of the image exemplars. An input image is analyzed using the trained local detectors, and a Bayesian objective function is derived for the input image from the non-parametric model and detector scores. The Bayesian objective function is optimized using a consensus of global models, and an output is generated with locations of the fiducial points labeled within the object in the image. \n",
      "Abstract 1 matchin: 10% -> Used Tokens: 529\n",
      "-------------------\n",
      "# 2 Clean Abstract: A Surveillance system is provided that includes at least one sensor disposed in a security area of a Surveillance region to sense an occurrence of a potential security breach event; a plurality of cameras is disposed in the Surveillance region; at least one camera thereof has a view of the security area and can be configured to automatically gather biometric infor mation concerning at least one subject person in the vicinity of the security area in response to the sensing of a potential security breach event; one or more other of the plurality of cameras can be configured to search for the at least one Subject person; a processing system is programmed to produce a dossier corresponding to the at least one subject person to match biometric information of one or more persons captured by one or more of the other cameras with corresponding biometric information in the dossier. \n",
      "Abstract 2 matchin: 20% -> Used Tokens: 524\n",
      "-------------------\n",
      "# 3 Clean Abstract: This specification describes technologies relating to biomet ric authentication based on images of the eye . In general , one aspect of the subject matter described in this specification can be embodied in methods that include obtaining images of a subject including a view of an eye . The methods may further include determining a behavioral metric based on detected movement of the eye as the eye appears in a plurality of the images , determining a spatial metric based on a distance from a sensor to a landmark that appears in a plurality of the images each having a different respective focus distance , and determining a reflectance metric based on detected changes in surface glare or specular reflection patterns on a surface of the eye . The methods may further include determining a score based on the behavioral , spatial , and reflectance metrics and rejecting or accepting the one or more images based on the score . ( \n",
      "Abstract 3 matchin: 20% -> Used Tokens: 529\n",
      "-------------------\n",
      "# 4 Clean Abstract: A user recognition method and apparatus , the user recogni tion method including performing a liveness test by extract ing a first feature of a first image acquired by capturing a user , and recognizing the user by extracting a second feature of the first image based on a result of the liveness test , is provided . a ( \n",
      "Abstract 4 matchin: 30% -> Used Tokens: 428\n",
      "-------------------\n",
      "# 5 Failed reading PDF.\n",
      "Failed abstract reconstructet. Used Tokens: 1187\n",
      "# 5 Reconstructed Abstract: Systems, devices, methods, and software are described for biometric sensors that permit a reduction in the size of the sensing area without significant reduction in biometric functionality of the sensor. A skin site of an individual is illuminated, and light scattered from the skin site is received. An image of a locally consistent feature of the skin site is formed from the received light. The locally consistent feature is analyzed to perform a biometric function.\n",
      "Abstract 5 matchin: 30% -> Used Tokens: 452\n",
      "-------------------\n",
      "# 6 Clean Abstract: System and method for detecting the authenticity of prod ucts by detecting a unique chaotic signature . Photos of the products are taken at the plant and stored in a database / server . The server processes the images to detect for each authentic product a unique authentic signature which is the result of a manufacturing process , a process of nature etc. To detect whether the product is genuine or not at the store , the user / buyer may take a picture of the product and send it to the server ( e.g. using an app installed on a portable device or the like ) . Upon receipt of the photo , the server may process the receive image in search for a pre - detected and / or pre - stored chaotic signature associated with an authentic product . The server may return a response to the user indicating the result of the search . A feedback mechanism may be included to guide the user to take a picture at a specific location of the product where the chaotic signature may exist . \n",
      "Abstract 6 matchin: 20% -> Used Tokens: 555\n",
      "-------------------\n",
      "# 7 Failed reading PDF.\n",
      "Failed abstract reconstructet. Used Tokens: 1108\n",
      "# 7 Reconstructed Abstract: A method, system, and computer program product for analyzing images of visual objects, such as currency and/or payment cards, captured on a mobile device. The analysis allows determining the authenticity and/or total amount of value of the currency and/or payment cards. The system may be used to verify the authenticity of hard currency, to count the total amount of the currency captured in one or more images, and to convert the currency using real time monetary exchange rates. The mobile device may be used to verify the identity of a credit card user by analyzing one or more images of the card holder's face and/or card holder's signature, card holder's name on the card, card number, and/or card security code.\n",
      "Abstract 7 matchin: 30% -> Used Tokens: 507\n",
      "-------------------\n",
      "# 8 Clean Abstract: Here, we introduce Z-webs, including Z-factors and Z-nodes, for the understanding of relationships between objects, sub jects, abstract ideas, concepts, or the like, including face, car, images, people, emotions, mood, text, natural language, Voice, music, video, locations, formulas, facts, historical data, landmarks, personalities, ownership, family, friends, love, happiness, Social behavior, Voting behavior, and the like, to be used for many applications in our life, including on the search engine, analytics, Big Data processing, natural language pro cessing, economy forecasting, face recognition, dealing with reliability and certainty, medical diagnosis, pattern recogni tion, object recognition, biometrics, security analysis, risk analysis, fraud detection, satellite image analysis, machine generated data analysis, machine learning, training samples, extracting data or patterns (from the video, images, and the like), editing video or images, and the like. Z-factors include reliability factor, confidence factor, expertise factor, bias fac tor, and the like, which is associated with each Z-node in the Z-web. \n",
      "Abstract 8 matchin: 20% -> Used Tokens: 596\n",
      "-------------------\n",
      "# 9 Clean Abstract: A portable device for personal identification using a dorsal hand vein-pattern in preferable configuration is disclosed. The mobile device utilizes an on-board camera operating in both visible and near infrared range, a memory unit, a pro cessor and Speeded-Up Robust Features algorithm for image acquisition, processing and comparison against the existing database of hand vein-pattern images. The matching criterion between the images to be used for the person's authentication. Device can optionally use wireless connection for image transferring and processing. \n",
      "Abstract 9 matchin: 30% -> Used Tokens: 460\n",
      "-------------------\n",
      "# 10 Clean Abstract: Mobile phones and other portable devices are equipped with a variety of technologies by which existing functionality can be improved , and new functionality can be provided . Some aspects relate to visual search capabilities , and determining appropriate actions responsive to different image inputs . Others relate to processing of image data . Still others concern metadata generation , processing , and representa tion . Yet others concern user interface improvements . Other aspects relate to imaging architectures , in which a mobile phone's image sensor is one in a chain of stages that successively act on packetized instructions / data , to capture and later process imagery . Still other aspects relate to distribution of processing tasks between the mobile device and remote resources ( “ the cloud ” ) . Elemental image pro cessing ( e.g. , simple filtering and edge detection ) can be performed on the mobile phone , while other operations can be referred out to remote service providers . The remote service providers can be selected using techniques such as reverse auctions , through which they compete for processing tasks . A great number of other features and arrangements are also detailed . ( \n",
      "Abstract 10 matchin: 10% -> Used Tokens: 572\n",
      "-------------------\n",
      "\n",
      "Insgesamt Tokens für diese Schleife: 7447\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "count_tokens = 0\n",
    "for i in pdf_list:\n",
    "    counter += 1\n",
    "    abstract = str(i)\n",
    "    removeHeadline = abstract.find(\"ABSTRACT\")\n",
    "    abstractOhneHeadline = abstract[removeHeadline+12:] #+12 um Überschrift \"ABSTRACT \\n \" ebenfalls zu entfernen\n",
    "    #print(abstractOhneHeadline)\n",
    "    split_abstr = abstractOhneHeadline.split('\\\\n ')\n",
    "    abstractOhneN = \"\".join(split_abstr)\n",
    "    finddigit = re.search(r\"\\d\",abstractOhneN)\n",
    "    x = finddigit.start()\n",
    "    clean_abstract = abstractOhneN[:x]\n",
    "    if (clean_abstract.count(\"\") > 5):\n",
    "        print(\"#\",counter,\"Clean Abstract:\",clean_abstract)\n",
    "        prompt = f\"\"\"```{example_abstract}```\\\n",
    "        Compare the abstract from the text above with the following abstract. Just tell me without explanation, how similar they are in percentage.\\\n",
    "        ```{clean_abstract}```\n",
    "        \"\"\"\n",
    "        response_abstract_comparison = get_completion(prompt)\n",
    "        erg = enc.encode(prompt)\n",
    "        tokens = len(erg)\n",
    "        print(\"Abstract\",counter,\"matchin:\",response_abstract_comparison,\"-> Used Tokens:\",tokens)\n",
    "        count_tokens += tokens\n",
    "        print(\"-------------------\")\n",
    "    else:\n",
    "        print(\"#\",counter,\"Failed reading PDF.\")\n",
    "        prompt_fail = f\"\"\"\n",
    "        The following text is mixed up with random words.\\\n",
    "        Extract the abstract.\\\n",
    "        Print the abstract without any additional explanation.\\\n",
    "        \\\n",
    "        ```{i}```\n",
    "        \"\"\"\n",
    "\n",
    "        reconstructed_abstract = get_completion(prompt_fail)\n",
    "        erg = enc.encode(prompt_fail)\n",
    "        tokens = len(erg)\n",
    "        print(\"Failed abstract reconstructet. Used Tokens:\",tokens)\n",
    "        count_tokens += tokens\n",
    "\n",
    "        print(\"#\",counter,\"Reconstructed Abstract:\",reconstructed_abstract)\n",
    "        prompt = f\"\"\"```{example_abstract}```\\\n",
    "        Compare the abstract from the text above with the following abstract. Just tell me without explanation, how similar they are in percentage.\\\n",
    "        ```{reconstructed_abstract}```\n",
    "        \"\"\"\n",
    "        response_abstract_comparison = get_completion(prompt)\n",
    "        erg = enc.encode(prompt)\n",
    "        tokens = len(erg)\n",
    "        print(\"Abstract\",counter,\"matchin:\",response_abstract_comparison,\"-> Used Tokens:\",tokens)\n",
    "        count_tokens += tokens\n",
    "        print(\"-------------------\")\n",
    "print(\"\\nInsgesamt Tokens für diese Schleife:\",count_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "print(len(pdf_list))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
