{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.output_parsers import StructuredOutputParser\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import datetime\n",
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = \"gpt-4\"\n",
    "\n",
    "\n",
    "def get_completion(prompt, model=llm_model):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"docs/Biometric Vehicle Access System.pdf\")\n",
    "pdf_abstract = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract1 = \"\"\"\n",
    "The Biometric Vehicle Access System (BVAS) is an innovative technology designed to revolutionize traditional vehicle security and access methods. This system employs advanced biometric authentication, including fingerprint and facial recognition, to ensure secure and convenient entry and ignition processes. BVAS enhances vehicle security by replacing traditional key-based and electronic fob systems with a seamless and personalized biometric verification process. The technology integrates biometric sensors into door handles, steering wheels, and ignition systems, allowing for quick and reliable user authentication. The BVAS not only provides an additional layer of security against unauthorized access but also enhances user convenience by eliminating the need for physical keys or key fobs. Users can effortlessly unlock, start, and operate their vehicles through a simple and rapid biometric scan. The system is designed with robust anti-spoofing measures to prevent unauthorized access attempts. Furthermore, BVAS contributes to the growing trend of biometric integration in smart vehicles, aligning with the industry's commitment to innovation, user experience, and safety. As vehicles continue to evolve into interconnected and autonomous entities, BVAS sets a new standard for personalized and secure access, catering to the increasing demand for sophisticated yet user-friendly solutions in the automotive sector.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract2 = \"\"\"\n",
    "The Biometric Vehicle Access System (BVAS) employs advanced fingerprint and facial recognition for secure and convenient vehicle entry. It replaces traditional key and fob systems with seamless biometric verification integrated into handles, steering wheels, and ignition. BVAS enhances security, eliminates the need for physical keys, and allows users to unlock and start their vehicles with a rapid biometric scan. The system includes anti-spoofing measures and aligns with the growing trend of biometric integration in smart vehicles, setting a new standard for personalized and secure access in the automotive sector.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract3 = \"\"\" \n",
    "BVAS revolutionizes vehicle security with advanced biometric authentication, eliminating keys for convenient entry. Integrated into handles and steering wheels, it sets a new standard for secure, user-friendly access, aligning with the trend of biometric integration in smart vehicles. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f\"\"\"```{pdf_abstract}```\\\n",
    "The abstract above describes a concept for a novel invention.\\\n",
    "I would like to search a patent database to find out whether \\\n",
    "there are already patents for such a concept. Name 5 phrases that I can \\\n",
    "use for the search. Each phrase should contain between 5 to 10 words. \\\n",
    "Optimize the phrases to get back more results.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = f\"\"\"```{pdf_abstract}```\\\n",
    "The abstract above describes a concept for a novel invention.\\\n",
    "I would like to search a patent database to find out whether \\\n",
    "there are already patents for such a concept. Please list me the codes of the 5 most relevant \\\n",
    "USPTO classifications to a possible patent for this concept without explanations for the codes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_keywords = get_completion(prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_classes = get_completion(prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \"Biometric Vehicle Access System technology\"\n",
      "2. \"Advanced biometric authentication in vehicles\"\n",
      "3. \"Biometric sensors in door handles and ignition systems\"\n",
      "4. \"Anti-spoofing measures in vehicle access\"\n",
      "5. \"Biometric integration in smart vehicles\"\n",
      "----\n",
      "1. G06K9/00\n",
      "2. B60R25/10\n",
      "3. G07C9/00\n",
      "4. E05B49/00\n",
      "5. G06F21/32\n"
     ]
    }
   ],
   "source": [
    "print(response_keywords)\n",
    "print(\"----\")\n",
    "print(response_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f = open('data_dump/test.json')\n",
    "\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1 :  Method and system for localizing parts of an object in an image for computer …\n",
      "https://patentimages.storage.googleapis.com/a2/95/38/bcc3b288e56669/US9275273.pdf \n",
      "\n",
      "Result 2 :  Adaptive multi-modal integrated biometric identification and surveillance …\n",
      "https://patentimages.storage.googleapis.com/98/f0/22/ae169ef67be168/US9432632.pdf \n",
      "\n",
      "Result 3 :  Spoof detection for biometric authentication\n",
      "https://patentimages.storage.googleapis.com/84/29/92/5fe2a153298d2d/US9971920.pdf \n",
      "\n",
      "Result 4 :  Liveness testing methods and apparatuses and image processing methods and …\n",
      "https://patentimages.storage.googleapis.com/b1/98/34/94c48fd1f99eeb/US11151397.pdf \n",
      "\n",
      "Result 5 :  Biometrics based on locally consistent features\n",
      "https://patentimages.storage.googleapis.com/a6/11/c7/5583de7c8fb29d/US9060688.pdf \n",
      "\n",
      "Result 6 :  System and method for detecting the authenticity of products\n",
      "https://patentimages.storage.googleapis.com/9c/e5/fc/eb90d460e518de/US10956732.pdf \n",
      "\n",
      "Result 7 :  System and process for automatically analyzing currency objects\n",
      "https://patentimages.storage.googleapis.com/da/c5/41/ea81c81c813087/US10504073.pdf \n",
      "\n",
      "Result 8 :  Application of Z-webs and Z-factors to analytics, search engine, learning, …\n",
      "https://patentimages.storage.googleapis.com/7a/fb/91/5ff09b40c62ec6/US8873813.pdf \n",
      "\n",
      "Result 9 :  Portable biometric identification device using a dorsal hand vein pattern\n",
      "https://patentimages.storage.googleapis.com/7c/30/05/2dc2f874122207/US9095285.pdf \n",
      "\n",
      "Result 10 :  Methods and systems for content processing\n",
      "https://patentimages.storage.googleapis.com/85/75/62/8ef916adcc3d18/US10922957.pdf \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in data['organic_results']:\n",
    "\n",
    "    print(\"Result\", i['position'], \": \", i['title'])\n",
    "    # print(i['snippet'], \"\\n\")\n",
    "    print(i['pdf'], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_list = []\n",
    "for i in data['organic_results']:\n",
    "    loader = PyPDFLoader(i['pdf'])\n",
    "    pdf = loader.load_and_split()\n",
    "    pdf_list.append(pdf[0])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='(12) United States Patent \\n Cheng et al. USOO9432632B2 \\n US 9.432,632 B2 \\n Aug. 30, 2016 (10) Patent No.: \\n (45) Date of Patent: \\n (54) ADAPTIVE MULTI-MODAL INTEGRATED \\n BOMETRIC IDENTIFICATION AND \\n SURVELLANCE SYSTEMS \\n (71) Applicant: Proximex Corporation, Cupertino, CA \\n (US) \\n (72) Inventors: Ken P. Cheng, Saratoga, CA (US); \\n Edward Y. Chang, Santa Barbara, CA (US); Yuan-Fang Wang, Goleta, CA \\n (US) \\n (73) Assignee: Proximex Corporation, Cupertino, CA \\n (US) \\n Subject to any disclaimer, the term of this patent is extended or adjusted under 35 \\n U.S.C. 154(b) by 0 days. \\n (21) Appl. No.: 14/607,201 \\n (22) Filed: Jan. 28, 2015 \\n (65) Prior Publication Data \\n US 2015/O138332 A1 May 21, 2015 \\n Related U.S. Application Data \\n (60) Division of application No. 13/738,655, filed on Jan. \\n 10, 2013, now Pat. No. 8,976,237, and a continuation of application No. 13/101,149, filed on May 5, 2011, \\n now Pat. No. 8.373,753, and a division of application (*) Notice: \\n (Continued) \\n (51) Int. Cl. \\n H04N 7/8 (2006.01) \\n A6 IB I/00 (2006.01) \\n (Continued) \\n (52) U.S. Cl. \\n CPC H04N 7/18 (2013.01); G06K 9/00 (2013.01); G06K 9/00288 (2013.01); \\n (Continued) \\n (58) Field of Classification Search \\n USPC ........... 348/77; 340/506; 358/143, 147, 161, \\n 358/169; 707/4, 103: 382/103, 209, 276, 382/277, 289, 291, 293, 294, 295, 282,305, \\n 382/115, 107, 190 See application file for complete search history. \\n (56) References Cited \\n U.S. PATENT DOCUMENTS \\n 5,258,837 A \\n 5,473,369 A 11/1993 Gormley \\n 12, 1995 Abe \\n (Continued) \\n FOREIGN PATENT DOCUMENTS \\n WO 2007/044037 A1 4/2007 \\n OTHER PUBLICATIONS \\n PCT/US05/44656 International Search Report and Written Opinion, \\n Jun. 26, 2006. \\n (Continued) \\n Primary Examiner — Jerome Grant, II \\n (74) Attorney, Agent, or Firm — Dean D. Small: The Small \\n Patent Law Group, LLC. \\n (57) ABSTRACT \\n A Surveillance system is provided that includes at least one sensor disposed in a security area of a Surveillance region to sense an occurrence of a potential security breach event; a plurality of cameras is disposed in the Surveillance region; at \\n least one camera thereof has a view of the security area and can be configured to automatically gather biometric infor mation concerning at least one subject person in the vicinity of the security area in response to the sensing of a potential \\n security breach event; one or more other of the plurality of cameras can be configured to search for the at least one Subject person; a processing system is programmed to \\n produce a dossier corresponding to the at least one subject \\n person to match biometric information of one or more persons captured by one or more of the other cameras with corresponding biometric information in the dossier. \\n 35 Claims, 8 Drawing Sheets \\n Apply Monitoring Rule on Security Area \\n configure device and Security Area specific parameters (Door, \\n restricted area, etc.) \\n Environment \\n (Map) Admin \\n Security Area \\n Admin display a sist of available Monitoring rules to apply to security area (Based on device characteristics Display a list of available devices to selecticeselect for applying Monitoring rule Select Security Area to configure Monitoring rule \\n Monitoring rule (Security Function) \\n Admin Configure Schedule & \\n Eable Rule to start monitoring configured \\n area Setect Cotstation Monitoring rule' metadata={'source': 'https://patentimages.storage.googleapis.com/98/f0/22/ae169ef67be168/US9432632.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "test_py = pdf_list[1]\n",
    "\n",
    "print(test_py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "page_content='(12) United States Patent \\n Cheng et al. USOO9432632B2 \\n US 9.432,632 B2 \\n Aug. 30, 2016 (10) Patent No.: \\n (45) Date of Patent: \\n (54) ADAPTIVE MULTI-MODAL INTEGRATED \\n BOMETRIC IDENTIFICATION AND \\n SURVELLANCE SYSTEMS \\n (71) Applicant: Proximex Corporation, Cupertino, CA \\n (US) \\n (72) Inventors: Ken P. Cheng, Saratoga, CA (US); \\n Edward Y. Chang, Santa Barbara, CA (US); Yuan-Fang Wang, Goleta, CA \\n (US) \\n (73) Assignee: Proximex Corporation, Cupertino, CA \\n (US) \\n Subject to any disclaimer, the term of this patent is extended or adjusted under 35 \\n U.S.C. 154(b) by 0 days. \\n (21) Appl. No.: 14/607,201 \\n (22) Filed: Jan. 28, 2015 \\n (65) Prior Publication Data \\n US 2015/O138332 A1 May 21, 2015 \\n Related U.S. Application Data \\n (60) Division of application No. 13/738,655, filed on Jan. \\n 10, 2013, now Pat. No. 8,976,237, and a continuation of application No. 13/101,149, filed on May 5, 2011, \\n now Pat. No. 8.373,753, and a division of application (*) Notice: \\n (Continued) \\n (51) Int. Cl. \\n H04N 7/8 (2006.01) \\n A6 IB I/00 (2006.01) \\n (Continued) \\n (52) U.S. Cl. \\n CPC H04N 7/18 (2013.01); G06K 9/00 (2013.01); G06K 9/00288 (2013.01); \\n (Continued) \\n (58) Field of Classification Search \\n USPC ........... 348/77; 340/506; 358/143, 147, 161, \\n 358/169; 707/4, 103: 382/103, 209, 276, 382/277, 289, 291, 293, 294, 295, 282,305, \\n 382/115, 107, 190 See application file for complete search history. \\n (56) References Cited \\n U.S. PATENT DOCUMENTS \\n 5,258,837 A \\n 5,473,369 A 11/1993 Gormley \\n 12, 1995 Abe \\n (Continued) \\n FOREIGN PATENT DOCUMENTS \\n WO 2007/044037 A1 4/2007 \\n OTHER PUBLICATIONS \\n PCT/US05/44656 International Search Report and Written Opinion, \\n Jun. 26, 2006. \\n (Continued) \\n Primary Examiner — Jerome Grant, II \\n (74) Attorney, Agent, or Firm — Dean D. Small: The Small \\n Patent Law Group, LLC. \\n (57) ABSTRACT \\n A Surveillance system is provided that includes at least one sensor disposed in a security area of a Surveillance region to sense an occurrence of a potential security breach event; a plurality of cameras is disposed in the Surveillance region; at \\n least one camera thereof has a view of the security area and can be configured to automatically gather biometric infor mation concerning at least one subject person in the vicinity of the security area in response to the sensing of a potential \\n security breach event; one or more other of the plurality of cameras can be configured to search for the at least one Subject person; a processing system is programmed to \\n produce a dossier corresponding to the at least one subject \\n person to match biometric information of one or more persons captured by one or more of the other cameras with corresponding biometric information in the dossier. \\n 35 Claims, 8 Drawing Sheets \\n Apply Monitoring Rule on Security Area \\n configure device and Security Area specific parameters (Door, \\n restricted area, etc.) \\n Environment \\n (Map) Admin \\n Security Area \\n Admin display a sist of available Monitoring rules to apply to security area (Based on device characteristics Display a list of available devices to selecticeselect for applying Monitoring rule Select Security Area to configure Monitoring rule \\n Monitoring rule (Security Function) \\n Admin Configure Schedule & \\n Eable Rule to start monitoring configured \\n area Setect Cotstation Monitoring rule' metadata={'source': 'https://patentimages.storage.googleapis.com/98/f0/22/ae169ef67be168/US9432632.pdf', 'page': 0}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die meisten Abstract scheinen mit \"ABSTRACT \\n\" zu beginnen und endet beim nächsten \"metadata=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pdf_list[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die enden nicht bei metadata, sondern die Class hängt die Metadaten am Ende einfach an. Deshalb \"enden\" die immer mit metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1898\n"
     ]
    }
   ],
   "source": [
    "abstract = str(test_py)\n",
    "print(abstract.find(\"ABSTRACT\"))\n",
    "removeHeadline = abstract.find(\"ABSTRACT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSTRACT \\n A Surveillance system is provided that includes at least one sensor disposed in a security area of a Surveillance region to sense an occurrence of a potential security breach event; a plurality of cameras is disposed in the Surveillance region; at \\n least one camera thereof has a view of the security area and can be configured to automatically gather biometric infor mation concerning at least one subject person in the vicinity of the security area in response to the sensing of a potential \\n security breach event; one or more other of the plurality of cameras can be configured to search for the at least one Subject person; a processing system is programmed to \\n produce a dossier corresponding to the at least one subject \\n person to match biometric information of one or more persons captured by one or more of the other cameras with corresponding biometric information in the dossier. \\n 35 Claims, 8 Drawing Sheets \\n Apply Monitoring Rule on Security Area \\n configure device and Security Area specific parameters (Door, \\n restricted area, etc.) \\n Environment \\n (Map) Admin \\n Security Area \\n Admin display a sist of available Monitoring rules to apply to security area (Based on device characteristics Display a list of available devices to selecticeselect for applying Monitoring rule Select Security Area to configure Monitoring rule \\n Monitoring rule (Security Function) \\n Admin Configure Schedule & \\n Eable Rule to start monitoring configured \\n area Setect Cotstation Monitoring rule' metadata={'source': 'https://patentimages.storage.googleapis.com/98/f0/22/ae169ef67be168/US9432632.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(abstract[removeHeadline:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Surveillance system is provided that includes at least one sensor disposed in a security area of a Surveillance region to sense an occurrence of a potential security breach event; a plurality of cameras is disposed in the Surveillance region; at \\n least one camera thereof has a view of the security area and can be configured to automatically gather biometric infor mation concerning at least one subject person in the vicinity of the security area in response to the sensing of a potential \\n security breach event; one or more other of the plurality of cameras can be configured to search for the at least one Subject person; a processing system is programmed to \\n produce a dossier corresponding to the at least one subject \\n person to match biometric information of one or more persons captured by one or more of the other cameras with corresponding biometric information in the dossier. \\n 35 Claims, 8 Drawing Sheets \\n Apply Monitoring Rule on Security Area \\n configure device and Security Area specific parameters (Door, \\n restricted area, etc.) \\n Environment \\n (Map) Admin \\n Security Area \\n Admin display a sist of available Monitoring rules to apply to security area (Based on device characteristics Display a list of available devices to selecticeselect for applying Monitoring rule Select Security Area to configure Monitoring rule \\n Monitoring rule (Security Function) \\n Admin Configure Schedule & \\n Eable Rule to start monitoring configured \\n area Setect Cotstation Monitoring rule' metadata={'source': 'https://patentimages.storage.googleapis.com/98/f0/22/ae169ef67be168/US9432632.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "abstractOhneHeadline = abstract[removeHeadline+12:] #+12 um Überschrift \"ABSTRACT \\n \" ebenfalls zu entfernen\n",
    "print(abstractOhneHeadline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A Surveillance system is provided that includes at least one sensor disposed in a security area of a Surveillance region to sense an occurrence of a potential security breach event; a plurality of cameras is disposed in the Surveillance region; at ', 'least one camera thereof has a view of the security area and can be configured to automatically gather biometric infor mation concerning at least one subject person in the vicinity of the security area in response to the sensing of a potential ', 'security breach event; one or more other of the plurality of cameras can be configured to search for the at least one Subject person; a processing system is programmed to ', 'produce a dossier corresponding to the at least one subject ', 'person to match biometric information of one or more persons captured by one or more of the other cameras with corresponding biometric information in the dossier. ', '35 Claims, 8 Drawing Sheets ', 'Apply Monitoring Rule on Security Area ', 'configure device and Security Area specific parameters (Door, ', 'restricted area, etc.) ', 'Environment ', '(Map) Admin ', 'Security Area ', 'Admin display a sist of available Monitoring rules to apply to security area (Based on device characteristics Display a list of available devices to selecticeselect for applying Monitoring rule Select Security Area to configure Monitoring rule ', 'Monitoring rule (Security Function) ', 'Admin Configure Schedule & ', 'Eable Rule to start monitoring configured ', \"area Setect Cotstation Monitoring rule' metadata={'source': 'https://patentimages.storage.googleapis.com/98/f0/22/ae169ef67be168/US9432632.pdf', 'page': 0}\"]\n",
      "A Surveillance system is provided that includes at least one sensor disposed in a security area of a Surveillance region to sense an occurrence of a potential security breach event; a plurality of cameras is disposed in the Surveillance region; at least one camera thereof has a view of the security area and can be configured to automatically gather biometric infor mation concerning at least one subject person in the vicinity of the security area in response to the sensing of a potential security breach event; one or more other of the plurality of cameras can be configured to search for the at least one Subject person; a processing system is programmed to produce a dossier corresponding to the at least one subject person to match biometric information of one or more persons captured by one or more of the other cameras with corresponding biometric information in the dossier. 35 Claims, 8 Drawing Sheets Apply Monitoring Rule on Security Area configure device and Security Area specific parameters (Door, restricted area, etc.) Environment (Map) Admin Security Area Admin display a sist of available Monitoring rules to apply to security area (Based on device characteristics Display a list of available devices to selecticeselect for applying Monitoring rule Select Security Area to configure Monitoring rule Monitoring rule (Security Function) Admin Configure Schedule & Eable Rule to start monitoring configured area Setect Cotstation Monitoring rule' metadata={'source': 'https://patentimages.storage.googleapis.com/98/f0/22/ae169ef67be168/US9432632.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "split_abstr = abstractOhneHeadline.split('\\\\n ')\n",
    "print(split_abstr)\n",
    "abstractOhneN = \"\".join(split_abstr)\n",
    "print(abstractOhneN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Surveillance system is provided that includes at least one sensor disposed in a security area of a Surveillance region to sense an occurrence of a potential security breach event; a plurality of cameras is disposed in the Surveillance region; at least one camera thereof has a view of the security area and can be configured to automatically gather biometric infor mation concerning at least one subject person in the vicinity of the security area in response to the sensing of a potential security breach event; one or more other of the plurality of cameras can be configured to search for the at least one Subject person; a processing system is programmed to produce a dossier corresponding to the at least one subject person to match biometric information of one or more persons captured by one or more of the other cameras with corresponding biometric information in the dossier. \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "finddigit = re.search(r\"\\d\",abstractOhneN)\n",
    "x = finddigit.start()\n",
    "clean_abstract = abstractOhneN[:x]\n",
    "print(clean_abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier folgt die Abstract-Bereinigung nochmals, jedoch als Scheleife für alle Abstracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1 Clean Abstract: A system is provided for localizing parts of an object in an image by training local detectors using labeled image exem plars with fiducial points corresponding to parts within the image. Each local detector generates a detector score corre sponding to the likelihood that a desired part is located at a given location within the image exemplar. A non-parametric global model of the locations of the fiducial points is gener ated for each of at least a portion of the image exemplars. An input image is analyzed using the trained local detectors, and a Bayesian objective function is derived for the input image from the non-parametric model and detector scores. The Bayesian objective function is optimized using a consensus of global models, and an output is generated with locations of the fiducial points labeled within the object in the image. \n",
      "# 2 Clean Abstract: A Surveillance system is provided that includes at least one sensor disposed in a security area of a Surveillance region to sense an occurrence of a potential security breach event; a plurality of cameras is disposed in the Surveillance region; at least one camera thereof has a view of the security area and can be configured to automatically gather biometric infor mation concerning at least one subject person in the vicinity of the security area in response to the sensing of a potential security breach event; one or more other of the plurality of cameras can be configured to search for the at least one Subject person; a processing system is programmed to produce a dossier corresponding to the at least one subject person to match biometric information of one or more persons captured by one or more of the other cameras with corresponding biometric information in the dossier. \n",
      "# 3 Clean Abstract: This specification describes technologies relating to biomet ric authentication based on images of the eye . In general , one aspect of the subject matter described in this specification can be embodied in methods that include obtaining images of a subject including a view of an eye . The methods may further include determining a behavioral metric based on detected movement of the eye as the eye appears in a plurality of the images , determining a spatial metric based on a distance from a sensor to a landmark that appears in a plurality of the images each having a different respective focus distance , and determining a reflectance metric based on detected changes in surface glare or specular reflection patterns on a surface of the eye . The methods may further include determining a score based on the behavioral , spatial , and reflectance metrics and rejecting or accepting the one or more images based on the score . ( \n",
      "# 4 Clean Abstract: A user recognition method and apparatus , the user recogni tion method including performing a liveness test by extract ing a first feature of a first image acquired by capturing a user , and recognizing the user by extracting a second feature of the first image based on a result of the liveness test , is provided . a ( \n",
      "# 5 Failed reading PDF.\n",
      "# 6 Clean Abstract: System and method for detecting the authenticity of prod ucts by detecting a unique chaotic signature . Photos of the products are taken at the plant and stored in a database / server . The server processes the images to detect for each authentic product a unique authentic signature which is the result of a manufacturing process , a process of nature etc. To detect whether the product is genuine or not at the store , the user / buyer may take a picture of the product and send it to the server ( e.g. using an app installed on a portable device or the like ) . Upon receipt of the photo , the server may process the receive image in search for a pre - detected and / or pre - stored chaotic signature associated with an authentic product . The server may return a response to the user indicating the result of the search . A feedback mechanism may be included to guide the user to take a picture at a specific location of the product where the chaotic signature may exist . \n",
      "# 7 Failed reading PDF.\n",
      "# 8 Clean Abstract: Here, we introduce Z-webs, including Z-factors and Z-nodes, for the understanding of relationships between objects, sub jects, abstract ideas, concepts, or the like, including face, car, images, people, emotions, mood, text, natural language, Voice, music, video, locations, formulas, facts, historical data, landmarks, personalities, ownership, family, friends, love, happiness, Social behavior, Voting behavior, and the like, to be used for many applications in our life, including on the search engine, analytics, Big Data processing, natural language pro cessing, economy forecasting, face recognition, dealing with reliability and certainty, medical diagnosis, pattern recogni tion, object recognition, biometrics, security analysis, risk analysis, fraud detection, satellite image analysis, machine generated data analysis, machine learning, training samples, extracting data or patterns (from the video, images, and the like), editing video or images, and the like. Z-factors include reliability factor, confidence factor, expertise factor, bias fac tor, and the like, which is associated with each Z-node in the Z-web. \n",
      "# 9 Clean Abstract: A portable device for personal identification using a dorsal hand vein-pattern in preferable configuration is disclosed. The mobile device utilizes an on-board camera operating in both visible and near infrared range, a memory unit, a pro cessor and Speeded-Up Robust Features algorithm for image acquisition, processing and comparison against the existing database of hand vein-pattern images. The matching criterion between the images to be used for the person's authentication. Device can optionally use wireless connection for image transferring and processing. \n",
      "# 10 Clean Abstract: Mobile phones and other portable devices are equipped with a variety of technologies by which existing functionality can be improved , and new functionality can be provided . Some aspects relate to visual search capabilities , and determining appropriate actions responsive to different image inputs . Others relate to processing of image data . Still others concern metadata generation , processing , and representa tion . Yet others concern user interface improvements . Other aspects relate to imaging architectures , in which a mobile phone's image sensor is one in a chain of stages that successively act on packetized instructions / data , to capture and later process imagery . Still other aspects relate to distribution of processing tasks between the mobile device and remote resources ( “ the cloud ” ) . Elemental image pro cessing ( e.g. , simple filtering and edge detection ) can be performed on the mobile phone , while other operations can be referred out to remote service providers . The remote service providers can be selected using techniques such as reverse auctions , through which they compete for processing tasks . A great number of other features and arrangements are also detailed . ( \n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in pdf_list:\n",
    "    counter += 1\n",
    "    abstract = str(i)\n",
    "    removeHeadline = abstract.find(\"ABSTRACT\")\n",
    "    abstractOhneHeadline = abstract[removeHeadline+12:] #+12 um Überschrift \"ABSTRACT \\n \" ebenfalls zu entfernen\n",
    "    #print(abstractOhneHeadline)\n",
    "    split_abstr = abstractOhneHeadline.split('\\\\n ')\n",
    "    abstractOhneN = \"\".join(split_abstr)\n",
    "    finddigit = re.search(r\"\\d\",abstractOhneN)\n",
    "    x = finddigit.start()\n",
    "    clean_abstract = abstractOhneN[:x]\n",
    "    if (clean_abstract.count(\"\") > 5):\n",
    "        print(\"#\",counter,\"Clean Abstract:\",clean_abstract)\n",
    "    else:\n",
    "        print(\"#\",counter,\"Failed reading PDF.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Ab hier folgt die Überprüfung der Ergebnisse; Lösung 1: Abgleich der Key Words und Classen</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobile phones and other portable devices are equipped with a variety of technologies by which existing functionality can be improved , and new functionality can be provided . Some aspects relate to visual search capabilities , and determining appropriate actions responsive to different image inputs . Others relate to processing of image data . Still others concern metadata generation , processing , and representa tion . Yet others concern user interface improvements . Other aspects relate to imaging architectures , in which a mobile phone's image sensor is one in a chain of stages that successively act on packetized instructions / data , to capture and later process imagery . Still other aspects relate to distribution of processing tasks between the mobile device and remote resources ( “ the cloud ” ) . Elemental image pro cessing ( e.g. , simple filtering and edge detection ) can be performed on the mobile phone , while other operations can be referred out to remote service providers . The remote service providers can be selected using techniques such as reverse auctions , through which they compete for processing tasks . A great number of other features and arrangements are also detailed . ( \n"
     ]
    }
   ],
   "source": [
    "print(clean_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f\"\"\"```{clean_abstract}```\\\n",
    "The abstract above describes a concept for a novel invention.\\\n",
    "I would like to search a patent database to find out whether \\\n",
    "there are already patents for such a concept. Name 5 phrases that I can \\\n",
    "use for the search. Each phrase should contain between 5 to 10 words. \\\n",
    "Optimize the phrases to get back more results.\n",
    "\"\"\"\n",
    "\n",
    "prompt2 = f\"\"\"```{clean_abstract}```\\\n",
    "The abstract above describes a concept for a novel invention.\\\n",
    "I would like to search a patent database to find out whether \\\n",
    "there are already patents for such a concept. Please list me the codes of the 5 most relevant \\\n",
    "USPTO classifications to a possible patent for this concept without explanations for the codes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_keywords_new = get_completion(prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_classes_new = get_completion(prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \"Visual search capabilities in mobile devices\"\n",
      "2. \"Image data processing in portable devices\"\n",
      "3. \"Metadata generation and representation in smartphones\"\n",
      "4. \"User interface improvements in mobile phones\"\n",
      "5. \"Imaging architectures in mobile phone's sensor\"\n",
      "----\n",
      "1. H04W 4/02\n",
      "2. G06F 3/0481\n",
      "3. G06K 9/00\n",
      "4. G06T 7/00\n",
      "5. H04N 5/232\n"
     ]
    }
   ],
   "source": [
    "print(response_keywords_new)\n",
    "print(\"----\")\n",
    "print(response_classes_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f\"\"\"```{response_keywords}```\\\n",
    "Compare the list above with the following list. Just tell without explanation, how similar they are in percentage.\\\n",
    "```{response_keywords_new}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_keywords_verification = get_completion(prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Word-Übereinstimmung: 10%\n"
     ]
    }
   ],
   "source": [
    "print(\"Key Word-Übereinstimmung:\",response_keywords_verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = f\"\"\"```{response_classes}```\\\n",
    "Compare the list above with the following list. Just tell me without explanation, how similar they are in percentage.\\\n",
    "```{response_classes_new}```\n",
    "\"\"\"\n",
    "\n",
    "response_classes_verification = get_completion(prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klassenübereinstimmung: 20%\n"
     ]
    }
   ],
   "source": [
    "print(\"Klassenübereinstimmung:\",response_classes_verification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Ab hier folgt die Überprüfung der Ergebnisse; Lösung 2: Abgleich der Abstracts insgesamt</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='US009060688B2 \\n (12) United States Patent (10) Patent No.: US 9,060,688 B2 \\n ROWe (45) Date of Patent: *Jun. 23, 2015 \\n (54) BIOMETRICS BASED ON LOCALLY A61B5/6838 (2013.01); A61 B 5/726 (2013.01); CONSISTENT FEATURES A61B 2562/0233 (2013.01); A61B 2562/046 \\n (2013.01); G06K9/00046 (2013.01); G06K (71) Applicant: LUMIDIGM, INC., Albuquerque, NM 9/28 (2013.01); G06K 2009/0006 (2013.01); (US) G06K 2009/00932 (2013.01); G07C 9/00158 (2013.01); A61 B 5/7264 (2013.01) \\n (72) Inventor: Robert K. Rowe, Corrales, NM (US) (58) Field of Classification Search USPC ......... 382/100, 115, 117, 124, 125, 128, 116, \\n (73) Assignee: HID GLOBAL CORPORATION, 382/191, 127, 149, 162, 312 Austin, TX (US) See application file for complete search history. \\n (*) Notice: Subject to any disclaimer, the term of this (56) References Cited \\n patent is extended or adjusted under 35 U.S.C. 154(b) by 0 days. U.S. PATENT DOCUMENTS \\n This patent is Subject to a terminal dis- 5,291.560 A * 3/1994 Daugman ..................... 382,117 \\n claimer. 5,812,252 A * 9/1998 Bowker et al. .................. 356/71 6,005,963 A * 12/1999 Bolle et al. ... ... 382,124 \\n 6,018,586 A * 1/2000 Kamei ....... ... 382,125 (21) Appl. No.: 13/624.361 6,041,410 A * 3/2000 Hsu et al. ... ... 713, 186 \\n 6,052.474. A * 4/2000 Nakayama . ... 382,124 (22) Filed: Sep. 21, 2012 6,175.407 B1 * 1/2001 Sartor ............ 356,71 \\n 6,356,649 B2 * 3/2002 Harkless et al. ... ... 382,115 \\n (65) Prior Publication Data 6.421,453 B1* 7/2002 Kanevsky et al. . ... 382,115 \\n 7,545,963 B2 * 6/2009 Rowe ................. ... 382,124 US 2013/OO22248A1 Jan. 24, 2013 7,809,168 B2 * 10/2010 Abiko et al. .................. 382,115 \\n (Continued) Related U.S. Application Dat e pplication Uata Primary Examiner — Vu Le \\n (63) Continuation of application No. 12/051,173, filed on Assistant Examiner — Aklilu Woldemariam \\n Mar. 19, 2008, now Pat. No. 8,285,010. (74) Attorney, Agent, or Firm — Marsh Fischmann & \\n (60) Provisional application No. 60/896,063, filed on Mar. Breyfogle LLP: Daniel J. Sherwinter \\n 21, 2007. (57) ABSTRACT \\n (51) Int. Cl. Systems, devices, methods, and software are described for \\n G06K 9/00 (2006.01) biometric sensors that permit a reduction in the size of the \\n A6 IB5/00 (2006.01) sensing area without significant reduction in biometric func \\n Ok 5.2. 7 3:08: tionality of the sensor. A skin site of an individual is illumi nated, and light scattered from the skin site is received. An GO7C 9/OO (2006.01) image of a locally consistent feature of the skin site is formed \\n (52) U.S. Cl. from the received light. The locally consistent feature is ana CPC ................ A61B5/0059 (2013.01); G06K 9/00 lyzed to perform a biometric function. \\n (2013.01); A61B5/0062 (2013.01); A61B 5/1172 (2013.01); A61 B 5/6826 (2013.01); \\n 100 N 24 Claims, 16 Drawing Sheets \\n 102 \\n 104' metadata={'source': 'https://patentimages.storage.googleapis.com/a6/11/c7/5583de7c8fb29d/US9060688.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "our_abstract = pdf_abstract\n",
    "print(pdf_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f\"\"\"```{our_abstract}```\\\n",
    "Compare the abstract from the text above with the following abstract. Just tell me without explanation, how similar they are in percentage.\\\n",
    "```{pdf_list[1]}```\n",
    "\"\"\"\n",
    "\n",
    "response_abstract_comparison = get_completion(prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract Übereinstimmung: 20%\n"
     ]
    }
   ],
   "source": [
    "print(\"Abstract Übereinstimmung:\",response_abstract_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avast, ye mystical mariners! Gather 'round as I unveil a tale of enchantment set to transform the ancient rites of safeguarding and embarking upon vessels of the seven seas. Picture this wondrous sorcery, if ye will—it harnesses the arcane power of biometrics, with fingerprint and visage recognition, to weave a spell of security and seamless entry into the very heart of the ship. Banish the bygone era of clunky keys and electronic trinkets, for this marvel unfolds a dance of biometric artistry that fortifies the ship's defenses with ethereal threads. The enchanted biometric sensors are deftly woven into door handles, steering wheels, and the ignition itself, allowing sailors to authenticate themselves with a mere flick of their fingers or a nod of their noble faces. And, lo and behold, it not only thwarts unwelcome interlopers but bids farewell to the age-old need for tangible keys or fobs. Sailors can now unlock, start, and commandeer their vessels with a swift and simple biometric incantation. Worry not, for the system is armed with anti-spoofing enchantments to repel any unauthorized buccaneers attempting to breach its magical wards.What's more, this mystical marvel aligns itself with the ever-shifting currents of progress, seamlessly integrating biometrics into the very essence of smart ships. It showcases the industry's unwavering commitment to the arcane arts of innovation, user delight, and safety on the treacherous seas. As vessels metamorphose into sentient and self-guided leviathans, this enchanting system sets a new standard for personalized and secure access, fulfilling the surging demand for swanky yet sailor-friendly solutions across the boundless realms of the ocean. Ahoy, and let the magic unfold!\n"
     ]
    }
   ],
   "source": [
    "our_abstract_but_pirate_and_magic = \"Avast, ye mystical mariners! Gather 'round as I unveil a tale of enchantment set to transform the ancient rites of safeguarding and embarking upon vessels of the seven seas. Picture this wondrous sorcery, if ye will—it harnesses the arcane power of biometrics, with fingerprint and visage \\\n",
    "recognition, to weave a spell of security and seamless entry into the very heart of the ship. Banish the bygone era of clunky keys and electronic trinkets, for this marvel unfolds a dance of biometric artistry that fortifies the ship's defenses with ethereal threads. The enchanted biometric sensors are deftly woven into door \\\n",
    "handles, steering wheels, and the ignition itself, allowing sailors to authenticate themselves with a mere flick of their fingers or a nod of their noble faces. And, lo and behold, it not only thwarts unwelcome interlopers but bids farewell to the age-old need for tangible keys or fobs. Sailors can now unlock, start, and commandeer their \\\n",
    "vessels with a swift and simple biometric incantation. Worry not, for the system is armed with anti-spoofing enchantments to repel any unauthorized buccaneers attempting to breach its magical wards.\\\n",
    "What's more, this mystical marvel aligns itself with the ever-shifting currents of progress, seamlessly integrating biometrics into the very essence of smart ships. It showcases the industry's unwavering commitment to the arcane arts of innovation, user delight, and safety on the treacherous seas. As vessels metamorphose into sentient and self-guided \\\n",
    "leviathans, this enchanting system sets a new standard for personalized and secure access, fulfilling the surging demand for swanky yet sailor-friendly solutions across the boundless realms of the ocean. Ahoy, and let the magic unfold!\"\n",
    "\n",
    "print(our_abstract_but_pirate_and_magic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract Übereinstimmung: 85%\n"
     ]
    }
   ],
   "source": [
    "prompt1 = f\"\"\"```{our_abstract}```\\\n",
    "Compare the abstract from the text above with the following abstract. Just tell me without explanation, how similar they are in percentage.\\\n",
    "```{our_abstract_but_pirate_and_magic}```\n",
    "\"\"\"\n",
    "\n",
    "response_abstract_comparison = get_completion(prompt1)\n",
    "print(\"Abstract Übereinstimmung:\",response_abstract_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract Übereinstimmung von Abtsract 1 bei: 10%\n",
      "Abstract Übereinstimmung von Abtsract 2 bei: 20%\n",
      "Abstract Übereinstimmung von Abtsract 3 bei: 50%\n",
      "Abstract Übereinstimmung von Abtsract 4 bei: 20%\n",
      "Abstract Übereinstimmung von Abtsract 5 bei: 5%\n",
      "Abstract Übereinstimmung von Abtsract 6 bei: 5%\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Rate limit reached for gpt-4 in organization org-bbfQbNCs4j79R29bdqHAUOjb on tokens_usage_based per min: Limit 10000, Used 9755, Requested 1209. Please try again in 5.784s. Visit https://platform.openai.com/account/rate-limits to learn more.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 10\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;66;03m#print(abstract)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124m```\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mour_abstract\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m```\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124mCompare the abstract from the text above with the following abstract. Just tell me without explanation, how similar they are in percentage.\u001b[39m\u001b[38;5;130;01m\\\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124m```\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m```\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 10\u001b[0m response_abstract_comparison \u001b[38;5;241m=\u001b[39m \u001b[43mget_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAbstract Übereinstimmung von Abtsract\u001b[39m\u001b[38;5;124m\"\u001b[39m,count,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbei:\u001b[39m\u001b[38;5;124m\"\u001b[39m,response_abstract_comparison)\n",
      "Cell \u001b[1;32mIn[2], line 6\u001b[0m, in \u001b[0;36mget_completion\u001b[1;34m(prompt, model)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_completion\u001b[39m(prompt, model\u001b[38;5;241m=\u001b[39mllm_model):\n\u001b[0;32m      5\u001b[0m     messages \u001b[38;5;241m=\u001b[39m [{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt}]\n\u001b[1;32m----> 6\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\s3phi\\anaconda3\\envs\\lab\\Lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TryAgain \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m>\u001b[39m start \u001b[38;5;241m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\s3phi\\anaconda3\\envs\\lab\\Lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[38;5;241m=\u001b[39m \u001b[43mrequestor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpost\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest_timeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[38;5;66;03m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\s3phi\\anaconda3\\envs\\lab\\Lib\\site-packages\\openai\\api_requestor.py:298\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, Tuple[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mfloat\u001b[39m]]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[0;32m    288\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[38;5;241m.\u001b[39mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[38;5;241m=\u001b[39mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[1;32m--> 298\u001b[0m     resp, got_stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    299\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resp, got_stream, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\s3phi\\anaconda3\\envs\\lab\\Lib\\site-packages\\openai\\api_requestor.py:700\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m    693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    694\u001b[0m             line, result\u001b[38;5;241m.\u001b[39mstatus_code, result\u001b[38;5;241m.\u001b[39mheaders, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    695\u001b[0m         )\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m parse_stream(result\u001b[38;5;241m.\u001b[39miter_lines())\n\u001b[0;32m    697\u001b[0m     ), \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    698\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[1;32m--> 700\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_interpret_response_line\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    704\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    705\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m    706\u001b[0m         \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    707\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\s3phi\\anaconda3\\envs\\lab\\Lib\\site-packages\\openai\\api_requestor.py:765\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    763\u001b[0m stream_error \u001b[38;5;241m=\u001b[39m stream \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mdata\n\u001b[0;32m    764\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stream_error \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m rcode \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m:\n\u001b[1;32m--> 765\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_error_response(\n\u001b[0;32m    766\u001b[0m         rbody, rcode, resp\u001b[38;5;241m.\u001b[39mdata, rheaders, stream_error\u001b[38;5;241m=\u001b[39mstream_error\n\u001b[0;32m    767\u001b[0m     )\n\u001b[0;32m    768\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Rate limit reached for gpt-4 in organization org-bbfQbNCs4j79R29bdqHAUOjb on tokens_usage_based per min: Limit 10000, Used 9755, Requested 1209. Please try again in 5.784s. Visit https://platform.openai.com/account/rate-limits to learn more."
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in pdf_list:\n",
    "    count += 1\n",
    "    abstract = i\n",
    "    #print(abstract)\n",
    "    prompt = f\"\"\"```{our_abstract}```\\\n",
    "    Compare the abstract from the text above with the following abstract. Just tell me without explanation, how similar they are in percentage.\\\n",
    "    ```{i}```\n",
    "    \"\"\"\n",
    "    response_abstract_comparison = get_completion(prompt)\n",
    "    print(\"Abstract Übereinstimmung von Abtsract\",count,\"bei:\",response_abstract_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b>Mit der Methode sprengen wir das Rate-Limit von gpt-4 (und auch 3.5)</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content=\"Biometric Vehic le Access S ystem  \\n \\nAbstract:  \\nThe Biometric Vehicle Access System (BVAS) is an innovative technology  designed to revolutionize \\ntraditional vehicle security and access methods.  \\nThis system employs advanced biometric authentication, including fingerprint and facial recognition, to \\nensure secure and convenient entry and ignition processes.  \\nBVAS enhances vehicle security by replacing traditional key -based and electronic fob systems with a \\nseamless and personalized biometric verification process. The technology  integrates biometric sensors \\ninto door handles, steering wheels, and ignition systems, allowing for quick and reliable user  \\nauthentication. The BVAS not only provides an additional layer of security  against unauthorized access but \\nalso enhances user convenience by eliminating the need for physical keys  or key fobs. Users can \\neffortlessly unlock, start, and operate their vehicles through a simple and rapid  biometric scan. The \\nsystem is designed with robust anti -spoofing measures to prevent unauthorized access attempts.  \\nFurthermore, BVAS contributes to the growing trend of biometric integration in smart vehicles, aligning \\nwith the industry's  commitment to innovation, user experience, and safety. As vehicles continue to evolve \\ninto interconnected and autonomous  entities, BVAS sets a new standard for personalized and secure \\naccess, catering to the increasing demand for sophisticated  yet user -friendly solutions in the automotive \\nsector.\", metadata={'source': 'docs/Biometric Vehicle Access System.pdf', 'page': 0})]\n"
     ]
    }
   ],
   "source": [
    "loader = PyPDFLoader('docs/Biometric Vehicle Access System.pdf')\n",
    "startpdf = loader.load_and_split()\n",
    "print(startpdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folgendes Abstract wurde eingelesen: A method, system, and computer program product for analyzing images of visual objects, such as currency and/or payment cards, captured on a mobile device. The analysis allows determining the authenticity and/or total amount of value of the currency and/or payment cards. The system may be used to verify the authenticity of hard currency, to count the total amount of the currency captured in one or more images, and to convert the currency using real time monetary exchange rates. The mobile device may be used to verify the identity of a credit card user by analyzing one or more images of the card holder's face and/or card holder's signature, card holder's name on the card, card number, and/or card security code.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Extract the abstract from the following item:\\\n",
    "```{abstract}```\n",
    "\"\"\"\n",
    "start_abstract = get_completion(prompt)\n",
    "print(\"Folgendes Abstract wurde eingelesen:\",start_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folgendes Abstract wurde eingelesen: A Surveillance system is provided that includes at least one sensor disposed in a security area of a Surveillance region to sense an occurrence of a potential security breach event; a plurality of cameras is disposed in the Surveillance region; at least one camera thereof has a view of the security area and can be configured to automatically gather biometric information concerning at least one subject person in the vicinity of the security area in response to the sensing of a potential security breach event; one or more other of the plurality of cameras can be configured to search for the at least one Subject person; a processing system is programmed to produce a dossier corresponding to the at least one subject person to match biometric information of one or more persons captured by one or more of the other cameras with corresponding biometric information in the dossier.\n"
     ]
    }
   ],
   "source": [
    "prompt = f\"\"\"Extract the abstract from the following item:\\\n",
    "```{pdf_list[1]}```\n",
    "\"\"\"\n",
    "abstract1 = get_completion(prompt)\n",
    "print(\"Folgendes Abstract wurde eingelesen:\",abstract1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "\n",
    "enc = tiktoken.get_encoding(\"cl100k_base\")\n",
    "erg = enc.encode(start_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A method, system, and computer program product for analyzing images of visual objects, such as currency and/or payment cards, captured on a mobile device. The analysis allows determining the authenticity and/or total amount of value of the currency and/or payment cards. The system may be used to verify the authenticity of hard currency, to count the total amount of the currency captured in one or more images, and to convert the currency using real time monetary exchange rates. The mobile device may be used to verify the identity of a credit card user by analyzing one or more images of the card holder's face and/or card holder's signature, card holder's name on the card, card number, and/or card security code.\n",
      "Benutzte Tokens: 141\n"
     ]
    }
   ],
   "source": [
    "print(start_abstract)\n",
    "print(\"Benutzte Tokens:\",len(erg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
