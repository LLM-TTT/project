{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from langchain.output_parsers import StructuredOutputParser\n",
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "import datetime\n",
    "import os\n",
    "import openai\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = \"gpt-4\"\n",
    "\n",
    "\n",
    "def get_completion(prompt, model=llm_model):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"docs/Biometric Vehicle Access System.pdf\")\n",
    "pdf_abstract = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract1 = \"\"\"\n",
    "The Biometric Vehicle Access System (BVAS) is an innovative technology designed to revolutionize traditional vehicle security and access methods. This system employs advanced biometric authentication, including fingerprint and facial recognition, to ensure secure and convenient entry and ignition processes. BVAS enhances vehicle security by replacing traditional key-based and electronic fob systems with a seamless and personalized biometric verification process. The technology integrates biometric sensors into door handles, steering wheels, and ignition systems, allowing for quick and reliable user authentication. The BVAS not only provides an additional layer of security against unauthorized access but also enhances user convenience by eliminating the need for physical keys or key fobs. Users can effortlessly unlock, start, and operate their vehicles through a simple and rapid biometric scan. The system is designed with robust anti-spoofing measures to prevent unauthorized access attempts. Furthermore, BVAS contributes to the growing trend of biometric integration in smart vehicles, aligning with the industry's commitment to innovation, user experience, and safety. As vehicles continue to evolve into interconnected and autonomous entities, BVAS sets a new standard for personalized and secure access, catering to the increasing demand for sophisticated yet user-friendly solutions in the automotive sector.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract2 = \"\"\"\n",
    "The Biometric Vehicle Access System (BVAS) employs advanced fingerprint and facial recognition for secure and convenient vehicle entry. It replaces traditional key and fob systems with seamless biometric verification integrated into handles, steering wheels, and ignition. BVAS enhances security, eliminates the need for physical keys, and allows users to unlock and start their vehicles with a rapid biometric scan. The system includes anti-spoofing measures and aligns with the growing trend of biometric integration in smart vehicles, setting a new standard for personalized and secure access in the automotive sector.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract3 = \"\"\" \n",
    "BVAS revolutionizes vehicle security with advanced biometric authentication, eliminating keys for convenient entry. Integrated into handles and steering wheels, it sets a new standard for secure, user-friendly access, aligning with the trend of biometric integration in smart vehicles. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f\"\"\"```{pdf_abstract}```\\\n",
    "The abstract above describes a concept for a novel invention.\\\n",
    "I would like to search a patent database to find out whether \\\n",
    "there are already patents for such a concept. Name 5 phrases that I can \\\n",
    "use for the search. Each phrase should contain between 5 to 10 words. \\\n",
    "Optimize the phrases to get back more results.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = f\"\"\"```{pdf_abstract}```\\\n",
    "The abstract above describes a concept for a novel invention.\\\n",
    "I would like to search a patent database to find out whether \\\n",
    "there are already patents for such a concept. Please list me the codes of the 5 most relevant \\\n",
    "USPTO classifications to a possible patent for this concept without explanations for the codes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_keywords = get_completion(prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_classes = get_completion(prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \"Biometric Vehicle Access System technology\"\n",
      "2. \"Advanced biometric authentication in vehicles\"\n",
      "3. \"Biometric sensors in door handles and ignition systems\"\n",
      "4. \"Anti-spoofing measures in vehicle access\"\n",
      "5. \"Biometric integration in smart vehicles\"\n",
      "----\n",
      "1. G06K9/00\n",
      "2. B60R25/10\n",
      "3. G07C9/00\n",
      "4. E05B49/00\n",
      "5. G06F21/32\n"
     ]
    }
   ],
   "source": [
    "print(response_keywords)\n",
    "print(\"----\")\n",
    "print(response_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "f = open('data_dump/test.json')\n",
    "\n",
    "data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result 1 :  Method and system for localizing parts of an object in an image for computer …\n",
      "https://patentimages.storage.googleapis.com/a2/95/38/bcc3b288e56669/US9275273.pdf \n",
      "\n",
      "Result 2 :  Adaptive multi-modal integrated biometric identification and surveillance …\n",
      "https://patentimages.storage.googleapis.com/98/f0/22/ae169ef67be168/US9432632.pdf \n",
      "\n",
      "Result 3 :  Spoof detection for biometric authentication\n",
      "https://patentimages.storage.googleapis.com/84/29/92/5fe2a153298d2d/US9971920.pdf \n",
      "\n",
      "Result 4 :  Liveness testing methods and apparatuses and image processing methods and …\n",
      "https://patentimages.storage.googleapis.com/b1/98/34/94c48fd1f99eeb/US11151397.pdf \n",
      "\n",
      "Result 5 :  Biometrics based on locally consistent features\n",
      "https://patentimages.storage.googleapis.com/a6/11/c7/5583de7c8fb29d/US9060688.pdf \n",
      "\n",
      "Result 6 :  System and method for detecting the authenticity of products\n",
      "https://patentimages.storage.googleapis.com/9c/e5/fc/eb90d460e518de/US10956732.pdf \n",
      "\n",
      "Result 7 :  System and process for automatically analyzing currency objects\n",
      "https://patentimages.storage.googleapis.com/da/c5/41/ea81c81c813087/US10504073.pdf \n",
      "\n",
      "Result 8 :  Application of Z-webs and Z-factors to analytics, search engine, learning, …\n",
      "https://patentimages.storage.googleapis.com/7a/fb/91/5ff09b40c62ec6/US8873813.pdf \n",
      "\n",
      "Result 9 :  Portable biometric identification device using a dorsal hand vein pattern\n",
      "https://patentimages.storage.googleapis.com/7c/30/05/2dc2f874122207/US9095285.pdf \n",
      "\n",
      "Result 10 :  Methods and systems for content processing\n",
      "https://patentimages.storage.googleapis.com/85/75/62/8ef916adcc3d18/US10922957.pdf \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in data['organic_results']:\n",
    "\n",
    "    print(\"Result\", i['position'], \": \", i['title'])\n",
    "    # print(i['snippet'], \"\\n\")\n",
    "    print(i['pdf'], \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_list = []\n",
    "for i in data['organic_results']:\n",
    "    loader = PyPDFLoader(i['pdf'])\n",
    "    pdf = loader.load_and_split()\n",
    "    pdf_list.append(pdf[0])\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='(12) United States Patent \\n Cheng et al. USOO9432632B2 \\n US 9.432,632 B2 \\n Aug. 30, 2016 (10) Patent No.: \\n (45) Date of Patent: \\n (54) ADAPTIVE MULTI-MODAL INTEGRATED \\n BOMETRIC IDENTIFICATION AND \\n SURVELLANCE SYSTEMS \\n (71) Applicant: Proximex Corporation, Cupertino, CA \\n (US) \\n (72) Inventors: Ken P. Cheng, Saratoga, CA (US); \\n Edward Y. Chang, Santa Barbara, CA (US); Yuan-Fang Wang, Goleta, CA \\n (US) \\n (73) Assignee: Proximex Corporation, Cupertino, CA \\n (US) \\n Subject to any disclaimer, the term of this patent is extended or adjusted under 35 \\n U.S.C. 154(b) by 0 days. \\n (21) Appl. No.: 14/607,201 \\n (22) Filed: Jan. 28, 2015 \\n (65) Prior Publication Data \\n US 2015/O138332 A1 May 21, 2015 \\n Related U.S. Application Data \\n (60) Division of application No. 13/738,655, filed on Jan. \\n 10, 2013, now Pat. No. 8,976,237, and a continuation of application No. 13/101,149, filed on May 5, 2011, \\n now Pat. No. 8.373,753, and a division of application (*) Notice: \\n (Continued) \\n (51) Int. Cl. \\n H04N 7/8 (2006.01) \\n A6 IB I/00 (2006.01) \\n (Continued) \\n (52) U.S. Cl. \\n CPC H04N 7/18 (2013.01); G06K 9/00 (2013.01); G06K 9/00288 (2013.01); \\n (Continued) \\n (58) Field of Classification Search \\n USPC ........... 348/77; 340/506; 358/143, 147, 161, \\n 358/169; 707/4, 103: 382/103, 209, 276, 382/277, 289, 291, 293, 294, 295, 282,305, \\n 382/115, 107, 190 See application file for complete search history. \\n (56) References Cited \\n U.S. PATENT DOCUMENTS \\n 5,258,837 A \\n 5,473,369 A 11/1993 Gormley \\n 12, 1995 Abe \\n (Continued) \\n FOREIGN PATENT DOCUMENTS \\n WO 2007/044037 A1 4/2007 \\n OTHER PUBLICATIONS \\n PCT/US05/44656 International Search Report and Written Opinion, \\n Jun. 26, 2006. \\n (Continued) \\n Primary Examiner — Jerome Grant, II \\n (74) Attorney, Agent, or Firm — Dean D. Small: The Small \\n Patent Law Group, LLC. \\n (57) ABSTRACT \\n A Surveillance system is provided that includes at least one sensor disposed in a security area of a Surveillance region to sense an occurrence of a potential security breach event; a plurality of cameras is disposed in the Surveillance region; at \\n least one camera thereof has a view of the security area and can be configured to automatically gather biometric infor mation concerning at least one subject person in the vicinity of the security area in response to the sensing of a potential \\n security breach event; one or more other of the plurality of cameras can be configured to search for the at least one Subject person; a processing system is programmed to \\n produce a dossier corresponding to the at least one subject \\n person to match biometric information of one or more persons captured by one or more of the other cameras with corresponding biometric information in the dossier. \\n 35 Claims, 8 Drawing Sheets \\n Apply Monitoring Rule on Security Area \\n configure device and Security Area specific parameters (Door, \\n restricted area, etc.) \\n Environment \\n (Map) Admin \\n Security Area \\n Admin display a sist of available Monitoring rules to apply to security area (Based on device characteristics Display a list of available devices to selecticeselect for applying Monitoring rule Select Security Area to configure Monitoring rule \\n Monitoring rule (Security Function) \\n Admin Configure Schedule & \\n Eable Rule to start monitoring configured \\n area Setect Cotstation Monitoring rule' metadata={'source': 'https://patentimages.storage.googleapis.com/98/f0/22/ae169ef67be168/US9432632.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "test_py = pdf_list[1]\n",
    "\n",
    "print(test_py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "page_content='(12) United States Patent \\n Cheng et al. USOO9432632B2 \\n US 9.432,632 B2 \\n Aug. 30, 2016 (10) Patent No.: \\n (45) Date of Patent: \\n (54) ADAPTIVE MULTI-MODAL INTEGRATED \\n BOMETRIC IDENTIFICATION AND \\n SURVELLANCE SYSTEMS \\n (71) Applicant: Proximex Corporation, Cupertino, CA \\n (US) \\n (72) Inventors: Ken P. Cheng, Saratoga, CA (US); \\n Edward Y. Chang, Santa Barbara, CA (US); Yuan-Fang Wang, Goleta, CA \\n (US) \\n (73) Assignee: Proximex Corporation, Cupertino, CA \\n (US) \\n Subject to any disclaimer, the term of this patent is extended or adjusted under 35 \\n U.S.C. 154(b) by 0 days. \\n (21) Appl. No.: 14/607,201 \\n (22) Filed: Jan. 28, 2015 \\n (65) Prior Publication Data \\n US 2015/O138332 A1 May 21, 2015 \\n Related U.S. Application Data \\n (60) Division of application No. 13/738,655, filed on Jan. \\n 10, 2013, now Pat. No. 8,976,237, and a continuation of application No. 13/101,149, filed on May 5, 2011, \\n now Pat. No. 8.373,753, and a division of application (*) Notice: \\n (Continued) \\n (51) Int. Cl. \\n H04N 7/8 (2006.01) \\n A6 IB I/00 (2006.01) \\n (Continued) \\n (52) U.S. Cl. \\n CPC H04N 7/18 (2013.01); G06K 9/00 (2013.01); G06K 9/00288 (2013.01); \\n (Continued) \\n (58) Field of Classification Search \\n USPC ........... 348/77; 340/506; 358/143, 147, 161, \\n 358/169; 707/4, 103: 382/103, 209, 276, 382/277, 289, 291, 293, 294, 295, 282,305, \\n 382/115, 107, 190 See application file for complete search history. \\n (56) References Cited \\n U.S. PATENT DOCUMENTS \\n 5,258,837 A \\n 5,473,369 A 11/1993 Gormley \\n 12, 1995 Abe \\n (Continued) \\n FOREIGN PATENT DOCUMENTS \\n WO 2007/044037 A1 4/2007 \\n OTHER PUBLICATIONS \\n PCT/US05/44656 International Search Report and Written Opinion, \\n Jun. 26, 2006. \\n (Continued) \\n Primary Examiner — Jerome Grant, II \\n (74) Attorney, Agent, or Firm — Dean D. Small: The Small \\n Patent Law Group, LLC. \\n (57) ABSTRACT \\n A Surveillance system is provided that includes at least one sensor disposed in a security area of a Surveillance region to sense an occurrence of a potential security breach event; a plurality of cameras is disposed in the Surveillance region; at \\n least one camera thereof has a view of the security area and can be configured to automatically gather biometric infor mation concerning at least one subject person in the vicinity of the security area in response to the sensing of a potential \\n security breach event; one or more other of the plurality of cameras can be configured to search for the at least one Subject person; a processing system is programmed to \\n produce a dossier corresponding to the at least one subject \\n person to match biometric information of one or more persons captured by one or more of the other cameras with corresponding biometric information in the dossier. \\n 35 Claims, 8 Drawing Sheets \\n Apply Monitoring Rule on Security Area \\n configure device and Security Area specific parameters (Door, \\n restricted area, etc.) \\n Environment \\n (Map) Admin \\n Security Area \\n Admin display a sist of available Monitoring rules to apply to security area (Based on device characteristics Display a list of available devices to selecticeselect for applying Monitoring rule Select Security Area to configure Monitoring rule \\n Monitoring rule (Security Function) \\n Admin Configure Schedule & \\n Eable Rule to start monitoring configured \\n area Setect Cotstation Monitoring rule' metadata={'source': 'https://patentimages.storage.googleapis.com/98/f0/22/ae169ef67be168/US9432632.pdf', 'page': 0}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die meisten Abstract scheinen mit \"ABSTRACT \\n\" zu beginnen und endet beim nächsten \"metadata=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(type(pdf_list[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die enden nicht bei metadata, sondern die Class hängt die Metadaten am Ende einfach an. Deshalb \"enden\" die immer mit metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1898\n"
     ]
    }
   ],
   "source": [
    "abstract = str(test_py)\n",
    "print(abstract.find(\"ABSTRACT\"))\n",
    "removeHeadline = abstract.find(\"ABSTRACT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ABSTRACT \\n A Surveillance system is provided that includes at least one sensor disposed in a security area of a Surveillance region to sense an occurrence of a potential security breach event; a plurality of cameras is disposed in the Surveillance region; at \\n least one camera thereof has a view of the security area and can be configured to automatically gather biometric infor mation concerning at least one subject person in the vicinity of the security area in response to the sensing of a potential \\n security breach event; one or more other of the plurality of cameras can be configured to search for the at least one Subject person; a processing system is programmed to \\n produce a dossier corresponding to the at least one subject \\n person to match biometric information of one or more persons captured by one or more of the other cameras with corresponding biometric information in the dossier. \\n 35 Claims, 8 Drawing Sheets \\n Apply Monitoring Rule on Security Area \\n configure device and Security Area specific parameters (Door, \\n restricted area, etc.) \\n Environment \\n (Map) Admin \\n Security Area \\n Admin display a sist of available Monitoring rules to apply to security area (Based on device characteristics Display a list of available devices to selecticeselect for applying Monitoring rule Select Security Area to configure Monitoring rule \\n Monitoring rule (Security Function) \\n Admin Configure Schedule & \\n Eable Rule to start monitoring configured \\n area Setect Cotstation Monitoring rule' metadata={'source': 'https://patentimages.storage.googleapis.com/98/f0/22/ae169ef67be168/US9432632.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "print(abstract[removeHeadline:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Surveillance system is provided that includes at least one sensor disposed in a security area of a Surveillance region to sense an occurrence of a potential security breach event; a plurality of cameras is disposed in the Surveillance region; at \\n least one camera thereof has a view of the security area and can be configured to automatically gather biometric infor mation concerning at least one subject person in the vicinity of the security area in response to the sensing of a potential \\n security breach event; one or more other of the plurality of cameras can be configured to search for the at least one Subject person; a processing system is programmed to \\n produce a dossier corresponding to the at least one subject \\n person to match biometric information of one or more persons captured by one or more of the other cameras with corresponding biometric information in the dossier. \\n 35 Claims, 8 Drawing Sheets \\n Apply Monitoring Rule on Security Area \\n configure device and Security Area specific parameters (Door, \\n restricted area, etc.) \\n Environment \\n (Map) Admin \\n Security Area \\n Admin display a sist of available Monitoring rules to apply to security area (Based on device characteristics Display a list of available devices to selecticeselect for applying Monitoring rule Select Security Area to configure Monitoring rule \\n Monitoring rule (Security Function) \\n Admin Configure Schedule & \\n Eable Rule to start monitoring configured \\n area Setect Cotstation Monitoring rule' metadata={'source': 'https://patentimages.storage.googleapis.com/98/f0/22/ae169ef67be168/US9432632.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "abstractOhneHeadline = abstract[removeHeadline+12:] #+12 um Überschrift \"ABSTRACT \\n \" ebenfalls zu entfernen\n",
    "print(abstractOhneHeadline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A Surveillance system is provided that includes at least one sensor disposed in a security area of a Surveillance region to sense an occurrence of a potential security breach event; a plurality of cameras is disposed in the Surveillance region; at ', 'least one camera thereof has a view of the security area and can be configured to automatically gather biometric infor mation concerning at least one subject person in the vicinity of the security area in response to the sensing of a potential ', 'security breach event; one or more other of the plurality of cameras can be configured to search for the at least one Subject person; a processing system is programmed to ', 'produce a dossier corresponding to the at least one subject ', 'person to match biometric information of one or more persons captured by one or more of the other cameras with corresponding biometric information in the dossier. ', '35 Claims, 8 Drawing Sheets ', 'Apply Monitoring Rule on Security Area ', 'configure device and Security Area specific parameters (Door, ', 'restricted area, etc.) ', 'Environment ', '(Map) Admin ', 'Security Area ', 'Admin display a sist of available Monitoring rules to apply to security area (Based on device characteristics Display a list of available devices to selecticeselect for applying Monitoring rule Select Security Area to configure Monitoring rule ', 'Monitoring rule (Security Function) ', 'Admin Configure Schedule & ', 'Eable Rule to start monitoring configured ', \"area Setect Cotstation Monitoring rule' metadata={'source': 'https://patentimages.storage.googleapis.com/98/f0/22/ae169ef67be168/US9432632.pdf', 'page': 0}\"]\n",
      "A Surveillance system is provided that includes at least one sensor disposed in a security area of a Surveillance region to sense an occurrence of a potential security breach event; a plurality of cameras is disposed in the Surveillance region; at least one camera thereof has a view of the security area and can be configured to automatically gather biometric infor mation concerning at least one subject person in the vicinity of the security area in response to the sensing of a potential security breach event; one or more other of the plurality of cameras can be configured to search for the at least one Subject person; a processing system is programmed to produce a dossier corresponding to the at least one subject person to match biometric information of one or more persons captured by one or more of the other cameras with corresponding biometric information in the dossier. 35 Claims, 8 Drawing Sheets Apply Monitoring Rule on Security Area configure device and Security Area specific parameters (Door, restricted area, etc.) Environment (Map) Admin Security Area Admin display a sist of available Monitoring rules to apply to security area (Based on device characteristics Display a list of available devices to selecticeselect for applying Monitoring rule Select Security Area to configure Monitoring rule Monitoring rule (Security Function) Admin Configure Schedule & Eable Rule to start monitoring configured area Setect Cotstation Monitoring rule' metadata={'source': 'https://patentimages.storage.googleapis.com/98/f0/22/ae169ef67be168/US9432632.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "split_abstr = abstractOhneHeadline.split('\\\\n ')\n",
    "print(split_abstr)\n",
    "abstractOhneN = \"\".join(split_abstr)\n",
    "print(abstractOhneN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Surveillance system is provided that includes at least one sensor disposed in a security area of a Surveillance region to sense an occurrence of a potential security breach event; a plurality of cameras is disposed in the Surveillance region; at least one camera thereof has a view of the security area and can be configured to automatically gather biometric infor mation concerning at least one subject person in the vicinity of the security area in response to the sensing of a potential security breach event; one or more other of the plurality of cameras can be configured to search for the at least one Subject person; a processing system is programmed to produce a dossier corresponding to the at least one subject person to match biometric information of one or more persons captured by one or more of the other cameras with corresponding biometric information in the dossier. \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "finddigit = re.search(r\"\\d\",abstractOhneN)\n",
    "x = finddigit.start()\n",
    "clean_abstract = abstractOhneN[:x]\n",
    "print(clean_abstract)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier folgt der die Abstract-Bereinigung nochmals, jedoch als Scheleife für alle Abstracts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 1 Clean Abstract: A system is provided for localizing parts of an object in an image by training local detectors using labeled image exem plars with fiducial points corresponding to parts within the image. Each local detector generates a detector score corre sponding to the likelihood that a desired part is located at a given location within the image exemplar. A non-parametric global model of the locations of the fiducial points is gener ated for each of at least a portion of the image exemplars. An input image is analyzed using the trained local detectors, and a Bayesian objective function is derived for the input image from the non-parametric model and detector scores. The Bayesian objective function is optimized using a consensus of global models, and an output is generated with locations of the fiducial points labeled within the object in the image. \n",
      "# 2 Clean Abstract: A Surveillance system is provided that includes at least one sensor disposed in a security area of a Surveillance region to sense an occurrence of a potential security breach event; a plurality of cameras is disposed in the Surveillance region; at least one camera thereof has a view of the security area and can be configured to automatically gather biometric infor mation concerning at least one subject person in the vicinity of the security area in response to the sensing of a potential security breach event; one or more other of the plurality of cameras can be configured to search for the at least one Subject person; a processing system is programmed to produce a dossier corresponding to the at least one subject person to match biometric information of one or more persons captured by one or more of the other cameras with corresponding biometric information in the dossier. \n",
      "# 3 Clean Abstract: This specification describes technologies relating to biomet ric authentication based on images of the eye . In general , one aspect of the subject matter described in this specification can be embodied in methods that include obtaining images of a subject including a view of an eye . The methods may further include determining a behavioral metric based on detected movement of the eye as the eye appears in a plurality of the images , determining a spatial metric based on a distance from a sensor to a landmark that appears in a plurality of the images each having a different respective focus distance , and determining a reflectance metric based on detected changes in surface glare or specular reflection patterns on a surface of the eye . The methods may further include determining a score based on the behavioral , spatial , and reflectance metrics and rejecting or accepting the one or more images based on the score . ( \n",
      "# 4 Clean Abstract: A user recognition method and apparatus , the user recogni tion method including performing a liveness test by extract ing a first feature of a first image acquired by capturing a user , and recognizing the user by extracting a second feature of the first image based on a result of the liveness test , is provided . a ( \n",
      "# 5 Failed reading PDF.\n",
      "# 6 Clean Abstract: System and method for detecting the authenticity of prod ucts by detecting a unique chaotic signature . Photos of the products are taken at the plant and stored in a database / server . The server processes the images to detect for each authentic product a unique authentic signature which is the result of a manufacturing process , a process of nature etc. To detect whether the product is genuine or not at the store , the user / buyer may take a picture of the product and send it to the server ( e.g. using an app installed on a portable device or the like ) . Upon receipt of the photo , the server may process the receive image in search for a pre - detected and / or pre - stored chaotic signature associated with an authentic product . The server may return a response to the user indicating the result of the search . A feedback mechanism may be included to guide the user to take a picture at a specific location of the product where the chaotic signature may exist . \n",
      "# 7 Failed reading PDF.\n",
      "# 8 Clean Abstract: Here, we introduce Z-webs, including Z-factors and Z-nodes, for the understanding of relationships between objects, sub jects, abstract ideas, concepts, or the like, including face, car, images, people, emotions, mood, text, natural language, Voice, music, video, locations, formulas, facts, historical data, landmarks, personalities, ownership, family, friends, love, happiness, Social behavior, Voting behavior, and the like, to be used for many applications in our life, including on the search engine, analytics, Big Data processing, natural language pro cessing, economy forecasting, face recognition, dealing with reliability and certainty, medical diagnosis, pattern recogni tion, object recognition, biometrics, security analysis, risk analysis, fraud detection, satellite image analysis, machine generated data analysis, machine learning, training samples, extracting data or patterns (from the video, images, and the like), editing video or images, and the like. Z-factors include reliability factor, confidence factor, expertise factor, bias fac tor, and the like, which is associated with each Z-node in the Z-web. \n",
      "# 9 Clean Abstract: A portable device for personal identification using a dorsal hand vein-pattern in preferable configuration is disclosed. The mobile device utilizes an on-board camera operating in both visible and near infrared range, a memory unit, a pro cessor and Speeded-Up Robust Features algorithm for image acquisition, processing and comparison against the existing database of hand vein-pattern images. The matching criterion between the images to be used for the person's authentication. Device can optionally use wireless connection for image transferring and processing. \n",
      "# 10 Clean Abstract: Mobile phones and other portable devices are equipped with a variety of technologies by which existing functionality can be improved , and new functionality can be provided . Some aspects relate to visual search capabilities , and determining appropriate actions responsive to different image inputs . Others relate to processing of image data . Still others concern metadata generation , processing , and representa tion . Yet others concern user interface improvements . Other aspects relate to imaging architectures , in which a mobile phone's image sensor is one in a chain of stages that successively act on packetized instructions / data , to capture and later process imagery . Still other aspects relate to distribution of processing tasks between the mobile device and remote resources ( “ the cloud ” ) . Elemental image pro cessing ( e.g. , simple filtering and edge detection ) can be performed on the mobile phone , while other operations can be referred out to remote service providers . The remote service providers can be selected using techniques such as reverse auctions , through which they compete for processing tasks . A great number of other features and arrangements are also detailed . ( \n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "for i in pdf_list:\n",
    "    counter += 1\n",
    "    abstract = str(i)\n",
    "    removeHeadline = abstract.find(\"ABSTRACT\")\n",
    "    abstractOhneHeadline = abstract[removeHeadline+12:] #+12 um Überschrift \"ABSTRACT \\n \" ebenfalls zu entfernen\n",
    "    #print(abstractOhneHeadline)\n",
    "    split_abstr = abstractOhneHeadline.split('\\\\n ')\n",
    "    abstractOhneN = \"\".join(split_abstr)\n",
    "    finddigit = re.search(r\"\\d\",abstractOhneN)\n",
    "    x = finddigit.start()\n",
    "    clean_abstract = abstractOhneN[:x]\n",
    "    if (clean_abstract.count(\"\") > 5):\n",
    "        print(\"#\",counter,\"Clean Abstract:\",clean_abstract)\n",
    "    else:\n",
    "        print(\"#\",counter,\"Failed reading PDF.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Ab hier folgt die Überprüfung der Ergebnisse; Lösung 1: Abgleich der Key Words und Classen</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mobile phones and other portable devices are equipped with a variety of technologies by which existing functionality can be improved , and new functionality can be provided . Some aspects relate to visual search capabilities , and determining appropriate actions responsive to different image inputs . Others relate to processing of image data . Still others concern metadata generation , processing , and representa tion . Yet others concern user interface improvements . Other aspects relate to imaging architectures , in which a mobile phone's image sensor is one in a chain of stages that successively act on packetized instructions / data , to capture and later process imagery . Still other aspects relate to distribution of processing tasks between the mobile device and remote resources ( “ the cloud ” ) . Elemental image pro cessing ( e.g. , simple filtering and edge detection ) can be performed on the mobile phone , while other operations can be referred out to remote service providers . The remote service providers can be selected using techniques such as reverse auctions , through which they compete for processing tasks . A great number of other features and arrangements are also detailed . ( \n"
     ]
    }
   ],
   "source": [
    "print(clean_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f\"\"\"```{clean_abstract}```\\\n",
    "The abstract above describes a concept for a novel invention.\\\n",
    "I would like to search a patent database to find out whether \\\n",
    "there are already patents for such a concept. Name 5 phrases that I can \\\n",
    "use for the search. Each phrase should contain between 5 to 10 words. \\\n",
    "Optimize the phrases to get back more results.\n",
    "\"\"\"\n",
    "\n",
    "prompt2 = f\"\"\"```{clean_abstract}```\\\n",
    "The abstract above describes a concept for a novel invention.\\\n",
    "I would like to search a patent database to find out whether \\\n",
    "there are already patents for such a concept. Please list me the codes of the 5 most relevant \\\n",
    "USPTO classifications to a possible patent for this concept without explanations for the codes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_keywords_new = get_completion(prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_classes_new = get_completion(prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. \"Visual search capabilities in mobile devices\"\n",
      "2. \"Image data processing in portable devices\"\n",
      "3. \"Metadata generation and representation in smartphones\"\n",
      "4. \"User interface improvements in mobile phones\"\n",
      "5. \"Imaging architectures in mobile phone's sensor\"\n",
      "----\n",
      "1. H04W 4/00\n",
      "2. G06F 3/01\n",
      "3. G06K 9/00\n",
      "4. G06T 7/00\n",
      "5. H04N 5/232\n"
     ]
    }
   ],
   "source": [
    "print(response_keywords_new)\n",
    "print(\"----\")\n",
    "print(response_classes_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f\"\"\"```{response_keywords}```\\\n",
    "Compare the list above with the following list. Just tell without explanation, how similar they are in percentage.\\\n",
    "```{response_keywords_new}```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_keywords_verification = get_completion(prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Key Word-Übereinstimmung: 10%\n"
     ]
    }
   ],
   "source": [
    "print(\"Key Word-Übereinstimmung:\",response_keywords_verification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = f\"\"\"```{response_classes}```\\\n",
    "Compare the list above with the following list. Just tell me without explanation, how similar they are in percentage.\\\n",
    "```{response_classes_new}```\n",
    "\"\"\"\n",
    "\n",
    "response_classes_verification = get_completion(prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klassenübereinstimmung: 20%\n"
     ]
    }
   ],
   "source": [
    "print(\"Klassenübereinstimmung:\",response_classes_verification)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Ab hier folgt die Überprüfung der Ergebnisse; Lösung 2: Abgleich der Abstracts insgesamt</b> \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='(12) United States Patent \\n Cheng et al. USOO9432632B2 \\n US 9.432,632 B2 \\n Aug. 30, 2016 (10) Patent No.: \\n (45) Date of Patent: \\n (54) ADAPTIVE MULTI-MODAL INTEGRATED \\n BOMETRIC IDENTIFICATION AND \\n SURVELLANCE SYSTEMS \\n (71) Applicant: Proximex Corporation, Cupertino, CA \\n (US) \\n (72) Inventors: Ken P. Cheng, Saratoga, CA (US); \\n Edward Y. Chang, Santa Barbara, CA (US); Yuan-Fang Wang, Goleta, CA \\n (US) \\n (73) Assignee: Proximex Corporation, Cupertino, CA \\n (US) \\n Subject to any disclaimer, the term of this patent is extended or adjusted under 35 \\n U.S.C. 154(b) by 0 days. \\n (21) Appl. No.: 14/607,201 \\n (22) Filed: Jan. 28, 2015 \\n (65) Prior Publication Data \\n US 2015/O138332 A1 May 21, 2015 \\n Related U.S. Application Data \\n (60) Division of application No. 13/738,655, filed on Jan. \\n 10, 2013, now Pat. No. 8,976,237, and a continuation of application No. 13/101,149, filed on May 5, 2011, \\n now Pat. No. 8.373,753, and a division of application (*) Notice: \\n (Continued) \\n (51) Int. Cl. \\n H04N 7/8 (2006.01) \\n A6 IB I/00 (2006.01) \\n (Continued) \\n (52) U.S. Cl. \\n CPC H04N 7/18 (2013.01); G06K 9/00 (2013.01); G06K 9/00288 (2013.01); \\n (Continued) \\n (58) Field of Classification Search \\n USPC ........... 348/77; 340/506; 358/143, 147, 161, \\n 358/169; 707/4, 103: 382/103, 209, 276, 382/277, 289, 291, 293, 294, 295, 282,305, \\n 382/115, 107, 190 See application file for complete search history. \\n (56) References Cited \\n U.S. PATENT DOCUMENTS \\n 5,258,837 A \\n 5,473,369 A 11/1993 Gormley \\n 12, 1995 Abe \\n (Continued) \\n FOREIGN PATENT DOCUMENTS \\n WO 2007/044037 A1 4/2007 \\n OTHER PUBLICATIONS \\n PCT/US05/44656 International Search Report and Written Opinion, \\n Jun. 26, 2006. \\n (Continued) \\n Primary Examiner — Jerome Grant, II \\n (74) Attorney, Agent, or Firm — Dean D. Small: The Small \\n Patent Law Group, LLC. \\n (57) ABSTRACT \\n A Surveillance system is provided that includes at least one sensor disposed in a security area of a Surveillance region to sense an occurrence of a potential security breach event; a plurality of cameras is disposed in the Surveillance region; at \\n least one camera thereof has a view of the security area and can be configured to automatically gather biometric infor mation concerning at least one subject person in the vicinity of the security area in response to the sensing of a potential \\n security breach event; one or more other of the plurality of cameras can be configured to search for the at least one Subject person; a processing system is programmed to \\n produce a dossier corresponding to the at least one subject \\n person to match biometric information of one or more persons captured by one or more of the other cameras with corresponding biometric information in the dossier. \\n 35 Claims, 8 Drawing Sheets \\n Apply Monitoring Rule on Security Area \\n configure device and Security Area specific parameters (Door, \\n restricted area, etc.) \\n Environment \\n (Map) Admin \\n Security Area \\n Admin display a sist of available Monitoring rules to apply to security area (Based on device characteristics Display a list of available devices to selecticeselect for applying Monitoring rule Select Security Area to configure Monitoring rule \\n Monitoring rule (Security Function) \\n Admin Configure Schedule & \\n Eable Rule to start monitoring configured \\n area Setect Cotstation Monitoring rule' metadata={'source': 'https://patentimages.storage.googleapis.com/98/f0/22/ae169ef67be168/US9432632.pdf', 'page': 0}\n"
     ]
    }
   ],
   "source": [
    "our_abstract = pdf_abstract\n",
    "print(pdf_list[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f\"\"\"```{our_abstract}```\\\n",
    "Compare the abstract from the text above with the following abstract. Just tell me without explanation, how similar they are in percentage.\\\n",
    "```{pdf_list[1]}```\n",
    "\"\"\"\n",
    "\n",
    "response_abstract_comparison = get_completion(prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstract Übereinstimmung: 20%\n"
     ]
    }
   ],
   "source": [
    "print(\"Abstract Übereinstimmung:\",response_abstract_comparison)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
